{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here a quick scan from the data from the fire-brigate department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Proj, transform\n",
    "from math import radians, cos, sin, asin, sqrt,atan2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projections(x,y, inProj, outProj):\n",
    "    \"\"\"\n",
    "    in this funtion we transform the data from the coordinate system to gps\n",
    "    \"\"\"\n",
    "    longitd, latitud = transform(inProj,outProj,x,y)\n",
    "    return longitd, latitud\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = (sin(dlat/2))**2 + cos(lat1) * cos(lat2) * (sin(dlon/2))**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "def pre_process_station_name(x):\n",
    "    \"\"\"\n",
    "    Standarized the station names. This step is necesary to merge different data sets later\n",
    "    \"\"\"\n",
    "    x = x.lower()        \n",
    "    x = x.split()    \n",
    "    return x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global station_locations, response_time_parameters \n",
    "response_time_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = pd.read_csv('data\\JADS\\incidenten_2017.csv', sep=';', decimal=',')\n",
    "df_dep = pd.read_csv('data\\JADS\\inzetten_2017.csv', sep=';', decimal=',')\n",
    "station_locations = pd.read_excel('data\\JADS\\kazernepositie en voertuigen.xlsx', sheet_name='adressen')\n",
    "station_locations['kazerne'] = station_locations['kazerne'].apply(lambda x: pre_process_station_name(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. General assesments of the datasets quality\n",
    "\n",
    "There are many incedents that are only on the deploy dataset. These incidents are demostrations. Thus, probably is better not to take them into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"the shape of the incidents dataset is {}\".format(df_in.shape))\n",
    "print(\"the shape of the deployment dataset is {}\".format(df_dep.shape))\n",
    "print(\"the time span of the data set incidents is: {}\".format((min(df_in['dim_datum_datum']), max(df_in['dim_datum_datum']))))\n",
    "print(print(\"the time span of the data set deploy is: {}\".format((min(df_dep['inzet_gealarmeerd_datumtijd']), \n",
    "                                                                  max(df_dep['inzet_gealarmeerd_datumtijd'])))))\n",
    "\n",
    "incidents_df_in = list(set(df_in['dim_incident_id'].unique()) - set(df_dep['hub_incident_id'].unique()))\n",
    "incidents_df_dep = list(set(df_dep['hub_incident_id'].unique()) - set(df_in['dim_incident_id'].unique()))\n",
    "\n",
    "print('the following id are only at incidents {}'.format(incidents_df_in))\n",
    "print('the following id are only at deploy {}'.format(len(incidents_df_dep)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('General statistics of the incident dataset')\n",
    "# print(df_in.describe().T.dropna()[['mean', 'std', 'min', 'max']])\n",
    "# print(\"\\n generak statistics of the deployment dataset: \\n\")\n",
    "# print(df_dep.describe().T.dropna()[['mean', 'std', 'min', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_dep.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EDA of the response time components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## 2.1 Relevant time slots for the response time\n",
    "\n",
    "In order to calculate the different components of the response time, we considered the folling information:\n",
    "\n",
    "\n",
    "(in) incident starts = dim_incident_start_datumtijd\n",
    "\n",
    "(in) incident finish = dim_incident_eind_datumtijd\n",
    "\n",
    "(dep) alarm is activated = inzet_gealarmeerd_datumtijd\n",
    "\n",
    "(dep) leave = inzet_uitgerukt_datumtijd\n",
    "\n",
    "(dep) arrive = inzet_terplaatse_datumtijd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(df_in, df_dep, station_locations):\n",
    "    \"\"\"\n",
    "    In this function we do all pre-processing necessary to calculate the different components of the response time.\n",
    "    \n",
    "    Note: the travel time depends on the speed and the incident location. Because the incident location is a \n",
    "    random variable, we only consider the speed parameters.\n",
    "    \n",
    "    Params\n",
    "    -------------------------------------------\n",
    "    df_in: data frame with the incident data\n",
    "    df_dep: data frame with the deployment data\n",
    "    station_locations: data frame with the fire station data\n",
    "    \n",
    "    Returns:\n",
    "    M: dataframe where every row includes all the relevant information of every deployment needed to calculate the response\n",
    "    time.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    inProj  = Proj(\"+init=EPSG:28992\", preserve_units=True)\n",
    "    outProj = Proj(\"+init=EPSG:4326\")\n",
    "\n",
    "\n",
    "    keep_in = ['dim_incident_id','st_x', 'st_y', 'dim_incident_incident_type', 'inc_dim_object_naam', \n",
    "               'dim_incident_start_datumtijd', 'dim_incident_eind_datumtijd', 'dim_prioriteit_prio']\n",
    "    \n",
    "    time_stamps = ['dim_incident_start_datumtijd', 'dim_incident_eind_datumtijd', 'inzet_gealarmeerd_datumtijd',\n",
    "                  'inzet_uitgerukt_datumtijd', 'inzet_terplaatse_datumtijd']\n",
    "    \n",
    "    keep_dep = ['hub_incident_id', 'inzet_uitgerukt_datumtijd', 'inzet_gealarmeerd_datumtijd','inzet_terplaatse_datumtijd', 'voertuig_groep',\n",
    "            'kazerne_groep', 'inzet_kazerne_naam']\n",
    "    \n",
    "    df_in = df_in[keep_in]\n",
    "    df_dep = df_dep[keep_dep]\n",
    "    \n",
    "    M = df_dep.merge(df_in, left_on='hub_incident_id', right_on='dim_incident_id', how = 'inner')\n",
    "    M['inzet_kazerne_naam'] = M['inzet_kazerne_naam'].apply(lambda x: pre_process_station_name(x))\n",
    "    \n",
    "    \n",
    "    # print(set(station_locations['kazerne'].unique()) - (set(station_locations['kazerne'].unique()) & set(M['inzet_kazerne_naam'].unique())))\n",
    "    M = station_locations.merge(M, left_on='kazerne', right_on='inzet_kazerne_naam', how = 'inner')\n",
    "    M['lon_in'], M['lat_in'] = np.vectorize(projections)(M['st_x'], M['st_y'], inProj, outProj)\n",
    "    M['haversine_distance (Km)'] = np.vectorize(haversine)(M['lon'], M['lat'], M['lon_in'], M['lat_in'])\n",
    "    \n",
    "    for date in time_stamps:\n",
    "        M[date] = pd.to_datetime(M[date])\n",
    "    \n",
    "    M['turn out time (seconds)'] = (M['inzet_uitgerukt_datumtijd'] - M['inzet_gealarmeerd_datumtijd']).astype('timedelta64[s]')\n",
    "    M['travel time (seconds)'] = (M['inzet_terplaatse_datumtijd'] - M['inzet_uitgerukt_datumtijd']).astype('timedelta64[s]')\n",
    "    M['response time (seconds)'] = M['turn out time (seconds)'] + M['travel time (seconds)'] + M['dispatch (seconds)']\n",
    "    M['Average Speed (Km/h)'] = M['haversine_distance (Km)']/(M['travel time (seconds)']/(60*60))\n",
    "    \n",
    "    #Some filters to remove outliers\n",
    "    M = M[(M['Average Speed (Km/h)']>0) & (M['Average Speed (Km/h)']<150)]\n",
    "    M = M[M['turn out time (seconds)']>0]\n",
    "    \n",
    "    return M.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "\n",
    "M = pre_process_data(df_in, df_dep, station_locations)\n",
    "M.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data issues:\n",
    "\n",
    "(a) no all the stations have dispatch time\n",
    "\n",
    "(b) There are some stations with different numbering. E.g, aalsmeer vrijwillig 1, aalsmeer vrijwillig 2. We will take only the first word for the deplyment dataset.\n",
    "\n",
    "(c) negrative time differences. E.g, activate the alarm before the calles was made\n",
    "\n",
    "(d) the station DRIEMOND does not have dispatch time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here, there are a couple of cases where the x and y coordinates are 0\n",
    "M.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_dist(df, variable, vehicle_type, kazerne, norm_val, alpha):\n",
    "    \"\"\"\n",
    "    Funtion to plot the time and speed distributions per station\n",
    "    \n",
    "    Parameters:\n",
    "    ------------------------------------------------\n",
    "    df: dataFrame\n",
    "    variable: the variables to be plotted from M\n",
    "    vehicle_type: the vehicle type of interest\n",
    "    kazerne: name of the station\n",
    "    norm_val: dataframe to store the results\n",
    "    alpha: threshold to define normality\n",
    "    \n",
    "    Return\n",
    "    ---------------------------------------------------\n",
    "    norm_val\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df[(df['kazerne']==kazerne) & (df['voertuig_groep'] == vehicle_type)]\n",
    "    priority_color = {1:'#d73027', 2:'#91bfdb'}\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14,10))\n",
    "    norm  = 'N'\n",
    "    \n",
    "    for dim_prioriteit_prio in [1,2]:\n",
    "        df_temp = df[df['dim_prioriteit_prio']==dim_prioriteit_prio]\n",
    "\n",
    "        # From https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html\n",
    "        try:\n",
    "            k2, p = stats.normaltest(df_temp[variable])\n",
    "            if p<alpha: norm = 'N-N'\n",
    "            \n",
    "        except ValueError:\n",
    "            norm = 'Null'\n",
    "            p = np.nan\n",
    "            \n",
    "        norm_val = norm_val.append(pd.Series([variable, kazerne, dim_prioriteit_prio, p, norm]), ignore_index=True)\n",
    "        ax = sns.distplot(df_temp[variable], bins=100, color=priority_color[dim_prioriteit_prio] ,\n",
    "                          label = 'Priority {} ({})'.format(dim_prioriteit_prio, norm))\n",
    "    \n",
    "    \n",
    "    ax.set(xlabel=variable, ylabel='', \n",
    "           title = 'Histogram and GKD of {} in the station: {} ({})'.format(variable, kazerne, vehicle_type))\n",
    "    fig.legend(loc='right')\n",
    "    path = 'figures/' + vehicle_type + '/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    fig.savefig(path + \"hist_ {}_{}_{}.png\".format(variable.replace(\"/\", \"\"), kazerne, vehicle_type))\n",
    "    \n",
    "    return norm_val\n",
    "    \n",
    "# var = ['response time (seconds)', 'turn out time (seconds)', 'Average Speed (Km/h)']\n",
    "\n",
    "# norm_val = pd.DataFrame()\n",
    "# alpha = 1e-3\n",
    "# for kazerne in M['kazerne'].unique():\n",
    "#     for v in var:\n",
    "#         for v_t in M['voertuig_groep'].unique():\n",
    "#             norm_val = plot_dist(M, v, v_t, kazerne, norm_val, alpha)\n",
    "        \n",
    "# norm_val.columns = ['var', 'kazerne', 'dim_prioriteit_prio', 'p', 'Normal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_dist(df, variable, fire_station, norm_val, alpha):\n",
    "    \"\"\"\n",
    "    Funtion to plot the time and speed distributions per station\n",
    "    \n",
    "    Parameters:\n",
    "    ------------------------------------------------\n",
    "    df: dataFrame\n",
    "    variable: the variables to be plotted from M\n",
    "    vehicle_type: the vehicle type of interest\n",
    "    kazerne: name of the station\n",
    "    norm_val: dataframe to store the results\n",
    "    alpha: threshold to define normality\n",
    "    \n",
    "    Return\n",
    "    ---------------------------------------------------\n",
    "    norm_val\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df[(df['kazerne'] == fire_station)]\n",
    "    priority_color = {1:'#d73027', 2:'#91bfdb'}\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14,10))\n",
    "    norm  = 'N'\n",
    "    \n",
    "    for priority in [1,2]:\n",
    "        df_temp = df[df['dim_prioriteit_prio']==priority]\n",
    "        \n",
    "        k2, p = stats.normaltest(df_temp[variable])\n",
    "        if p<alpha: \n",
    "            norm = 'N-N'\n",
    "        \n",
    "        norm_val = norm_val.append(pd.Series([variable, fire_station, priority, p, norm]), ignore_index=True)\n",
    "        ax = sns.distplot(df_temp[variable], bins=100, color=priority_color[priority] ,\n",
    "                          label = 'Priority {} ({})'.format(priority, norm))\n",
    "    \n",
    "    \n",
    "    ax.set(xlabel=var, ylabel='', \n",
    "           title = 'Histogram and GKD of {} in the station: {}'.format(variable, fire_station, priority))\n",
    "    fig.legend(loc='right')\n",
    "    \n",
    "    fig.savefig(\"figures/hist_ {}_{}.png\".format(variable.replace(\"/\", \"\"), kazerne))\n",
    "    \n",
    "    return norm_val\n",
    "    \n",
    "variable = ['haversine_distance (Km)', 'turn out time (seconds)', \n",
    "       'response time (seconds)', 'Average Speed (Km/h)']\n",
    "\n",
    "norm_val = pd.DataFrame()\n",
    "alpha = 1e-3\n",
    "for fire_station in M['kazerne'].unique():\n",
    "    for v in var:\n",
    "        norm_val = plot_dist(M, v, fire_station, norm_val, alpha)\n",
    "        \n",
    "norm_val.columns = ['var', 'kazerne', 'dim_prioriteit_prio', 'p', 'Normal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simulation functions\n",
    "\n",
    "Thise funtions will be later on included in the main class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General satistics, this information can be used as an input ot the simulation model\n",
    "\n",
    "def create_global_time_parameters(M):\n",
    "    \"\"\"\n",
    "    Calculate different aggregate levels of the time dependent parameters\n",
    "    \n",
    "    Params:\n",
    "    ------------------------------------------\n",
    "    M: see funtion pre_process_data\n",
    "    \n",
    "    Return\n",
    "    -----------------------------------------\n",
    "    Global dictionary response_time_parameters that have three levels of aggregation. Level one is the less aggregated level  \n",
    "    \n",
    "    \"\"\"\n",
    "    # We only include priority one and two incidents\n",
    "    M = M[M['dim_prioriteit_prio'] <3]\n",
    "    \n",
    "\n",
    "    \n",
    "    response_time_parameters['level_1'] = M.groupby(['kazerne', 'dim_prioriteit_prio', 'voertuig_groep'], as_index=False).agg({\n",
    "                                                                  'dispatch (seconds)':['mean','std', 'count'],\n",
    "                                                                  'turn out time (seconds)':['mean','std', 'count'],\n",
    "                                                                  'response time (seconds)':['mean','std', 'count'],\n",
    "                                                                  'Average Speed (Km/h)':['mean','std', 'count']}).dropna()\n",
    "\n",
    "    \n",
    "    response_time_parameters['level_2'] = M.groupby([ 'dim_prioriteit_prio', 'voertuig_groep'], as_index=False).agg({\n",
    "                                                                  'dispatch (seconds)':['mean','std', 'count'],\n",
    "                                                                  'turn out time (seconds)':['mean','std', 'count'],\n",
    "                                                                  'response time (seconds)':['mean','std', 'count'],\n",
    "                                                                  'Average Speed (Km/h)':['mean','std', 'count']}).dropna()\n",
    "    \n",
    "    response_time_parameters['level_3'] = M.groupby(['voertuig_groep'], as_index=False).agg({\n",
    "                                                                  'dispatch (seconds)':['mean','std', 'count'],\n",
    "                                                                  'turn out time (seconds)':['mean','std', 'count'],\n",
    "                                                                  'response time (seconds)':['mean','std', 'count'],\n",
    "                                                                  'Average Speed (Km/h)':['mean','std', 'count']}).dropna()\n",
    "    \n",
    "\n",
    "create_global_time_parameters(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_statistical_significance(df, n=20):\n",
    "    \"\"\"\n",
    "    check if the filtered subset is statistical significant\n",
    "    \n",
    "    Parameters\n",
    "    ----------------------------------------\n",
    "    df: dataFrame with the parameter of the filter made at the funtion get_parameters\n",
    "    n: minimun number of observations to consider the parameters as significant\n",
    "    \n",
    "    Return\n",
    "    -----------------------------------------\n",
    "    True if the parameters are statistically significant, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    names = df.columns.get_level_values(level=0).unique()[0:3]\n",
    "    try:\n",
    "        statistical_significance = df['turn out time (seconds)']['count'].values < n\n",
    "        statistical_significance = statistical_significance[0]\n",
    "        print('No enougth observations, the minumin is n={}'.format(n))\n",
    "        \n",
    "    except IndexError:\n",
    "        print('Empty dataFrame')\n",
    "        statistical_significance = True\n",
    "    \n",
    "    if statistical_significance:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "            \n",
    "def get_parameters(station, vehicle, incident_priority):\n",
    "    \"\"\"\n",
    "    get the mean and standar deviation of the time distribution of the required sources\n",
    "    \n",
    "    Parameters\n",
    "    ----------------------------------------------\n",
    "    See the response_time_simulation parameters\n",
    "    \n",
    "    Return\n",
    "    --------------------------------------------\n",
    "    lower aggregated parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Level one of aggregation\n",
    "    parameters = response_time_parameters['level_1'][ \n",
    "                                         (response_time_parameters['level_1']['kazerne'] == station) & \n",
    "                                         (response_time_parameters['level_1']['dim_prioriteit_prio'] == incident_priority) &\n",
    "                                         (response_time_parameters['level_1']['voertuig_groep'] == vehicle)\n",
    "                                         ]\n",
    "\n",
    "    if check_statistical_significance(parameters):\n",
    "        print('getting the parameters from level_1 of the vehicle {}'.format(vehicle))\n",
    "        return parameters\n",
    "    \n",
    "    # Level two of aggregation\n",
    "    parameters = response_time_parameters['level_2'][  \n",
    "                                         (response_time_parameters['level_2']['dim_prioriteit_prio'] == incident_priority) &\n",
    "                                         (response_time_parameters['level_2']['voertuig_groep'] == vehicle)\n",
    "                                         ]\n",
    "        \n",
    "    if check_statistical_significance(parameters):\n",
    "        print('getting the parameters from level_2 of the vehicle {}'.format(vehicle))\n",
    "        return parameters\n",
    "    \n",
    "    # Level one of aggregation\n",
    "    parameters = response_time_parameters['level_3'][  \n",
    "                                         (response_time_parameters['level_3']['voertuig_groep'] == vehicle)\n",
    "                                         ]\n",
    "    print('getting the parameters from level_3 of the vehicle {}'.format(vehicle))\n",
    "    \n",
    "    return parameters\n",
    "    \n",
    "\n",
    "\n",
    "def get_simulated_values(station, vehicle, incident_priority, incident_location):\n",
    "    \"\"\"\n",
    "    Function to calculate the simulated value\n",
    "    \n",
    "    Paramters:\n",
    "    ------------------------------------------\n",
    "    see response_time_simulation\n",
    "    \n",
    "    Return\n",
    "    ----------------------------------------\n",
    "    x: random value x that assumes normal ditsribution\n",
    "    \"\"\"\n",
    "    x = {}\n",
    "    parameters = get_parameters(station, vehicle, incident_priority)\n",
    "    if parameters is None:\n",
    "        return parameters\n",
    "    \n",
    "    reponse_time = 0.\n",
    "    for var in list(response_time_parameters['level_1'].columns.get_level_values(level=0).unique()[3::]):\n",
    "        temp_par = parameters[var]\n",
    "        x[var] = max(np.random.normal(temp_par['mean'], temp_par['std'], 1), 0.001)\n",
    "        reponse_time += x[var]\n",
    "        \n",
    "    station_locations[station_locations['kazerne'] == station][['lon', 'lat']]\n",
    "    distance_km = haversine(incident_location[1], incident_location[0], \n",
    "                            station_locations[station_locations['kazerne'] == station]['lon'], \n",
    "                            station_locations[station_locations['kazerne'] == station]['lat'])\n",
    "    \n",
    "    \n",
    "    x['travel time (sec)'] = 1/(x['Average Speed (Km/h)'] / distance_km / 60 / 60)\n",
    "    x['response time (seconds)'] = x['dispatch (seconds)'] + x['turn out time (seconds)'] + x['travel time (sec)']\n",
    "    return x\n",
    "    \n",
    "    \n",
    "def response_time_simulation(station, incident_priority, incident_location, vehicle_type):\n",
    "    \"\"\"\n",
    "    Calculate the simulated response time per vehicle. We assume normality on the time distributions\n",
    "    \n",
    "    Parameters\n",
    "    --------------------------------------------\n",
    "    station: The station that is going to be used to deploy the vehicles\n",
    "    incident_priority: (str) is the priority of the incident (dim_prioriteit_prio)\n",
    "    incident_location: [latitud, longitud] latitud and longitud of the incident\n",
    "    vehicle_type: [] list with the vehicles that will to be deployed \n",
    "    \n",
    "    Return\n",
    "    --------------------------------------------\n",
    "    response_time = (dict) every time component per vehicle type\n",
    "    \"\"\"\n",
    "    response_time = {}\n",
    "    vehicle, freq = np.unique(vehicle_type, return_counts=True)\n",
    "    for v, iter_ in zip(vehicle, freq):\n",
    "        for i in range(iter_):\n",
    "            response_time[v + '_' + str(i)] = get_simulated_values(station, v, incident_priority, incident_location)\n",
    "            \n",
    "    return response_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for the response time\n",
    "station = 'aalsmeer'\n",
    "incident_priority = 2\n",
    "incident_location = [52.2538, 4.76889]\n",
    "vehicle_type = ['TS', 'Middelen', 'TS', 'Overig']\n",
    "response_time = response_time_simulation(station, incident_priority, incident_location, vehicle_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
