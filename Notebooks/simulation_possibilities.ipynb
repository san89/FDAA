{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation possibilities\n",
    "\n",
    "This notebook looks into some simulation ideas for the FDAA case. It tests certain assumptions and distributions to support the design of the simulation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_csv(\"../Data/incidenten_2017.csv\", sep=\";\", decimal=\",\")\n",
    "deployments = pd.read_csv(\"../Data/inzetten_2017.csv\", sep=\";\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Interarrival times\n",
    "\n",
    "If there is a distribution to be found in the interarrival times of incidents in a demand location / postal code, we can use this to simulate the timing of incidents efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 most busy postal codes\n",
    "postcodes = ['1012', '1013', '1017', '1102', '1018', '1069', '1016', '1068', '1097', '1055']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents[\"dim_incident_postcode_digits\"] = incidents[\"dim_incident_postcode\"].str[0:4]\n",
    "incidents[\"dim_incident_start_datumtijd\"] = pd.to_datetime(incidents[\"dim_incident_start_datumtijd\"])\n",
    "incidents.sort_values(\"dim_incident_start_datumtijd\", ascending=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = incidents[np.isin(incidents[\"dim_incident_postcode_digits\"], postcodes)]\n",
    "intertimes = top10.groupby(\"dim_incident_postcode_digits\").apply(lambda x: \n",
    "                                                                 x.sort_values(\"dim_incident_start_datumtijd\", ascending=True)\\\n",
    "                                                                 [\"dim_incident_start_datumtijd\"].diff(1)[1:].dt.seconds/3600)\\\n",
    "                                                          .reset_index(level=1, drop=True)\\\n",
    "                                                          .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(30,10))\n",
    "\n",
    "for i in range(len(postcodes)):\n",
    "    \n",
    "    temp = intertimes[intertimes[\"dim_incident_postcode_digits\"]==postcodes[i]]\n",
    "    \n",
    "    if i >= 5:\n",
    "        axes[1,i-5].hist(temp[\"dim_incident_start_datumtijd\"], bins=50)\n",
    "    else: \n",
    "        axes[0,i].hist(temp[\"dim_incident_start_datumtijd\"], bins=50)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not seem to be a clear distribution in these interarrival times. One might say they are completely random. Maybe a Poisson distribution is suitable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents[\"interarrival_time\"] = incidents[\"dim_incident_start_datumtijd\"].diff().dt.seconds / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents[\"interarrival_time\"].max() / (60*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents[\"interarrival_time\"].astype(float).hist(bins=200, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In 2017, there were {} incidents that occurred within 1 minute of the previous incident.\".format(sum(incidents[\"interarrival_time\"] < 1)))\n",
    "print(\"{} incidents occurred within one hour of the previous incident (total incidents: {}).\".format(sum(incidents[\"interarrival_time\"] < 60), len(incidents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look only at peak time: between 10 AM and 8 PM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents[\"dim_tijd_dagdeel\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_incidents = incidents[(incidents[\"dim_tijd_uur\"]>=10)&(incidents[\"dim_tijd_uur\"]<20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_incidents[\"interarrival_time\"].astype(float).hist(bins=200, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = peak_incidents[\"interarrival_time\"].mean()\n",
    "print(\"Average interarrival time: {}\".format(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try exponential interarrival rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.exponential(L, len(incidents))\n",
    "y = incidents[\"interarrival_time\"].astype(float)\n",
    "labels=[\"simulated\", \"actual\"]\n",
    "\n",
    "def plot_double_hist(x, y, labels, bins=200, xlim=250):\n",
    "    fig, ax = plt.subplots(figsize=(15,7))\n",
    "    #plt.hist(x, bins=200, alpha=0.7)\n",
    "    #plt.hist(y, bins=200, alpha=0.7)\n",
    "    ax.hist([x,y], label=labels, bins=bins)\n",
    "    ax.set_xlim((0,xlim))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_double_hist(x, y, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = peak_incidents[\"interarrival_time\"].astype(float)\n",
    "x = np.random.exponential(L, len(peak_incidents))\n",
    "plot_double_hist(x, y2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>The interarrival times seem to exactly follow the exponential distribution, at least if we look at all events in the whole safety region.</strong>\n",
    "\n",
    "<p>We could sample from this distribution and then sample the demand location as a multinomial. Alternatively, we could see if this distribution also holds for separate \"demand locations\" (e.g. postcodes), so that we can simulate the arrivals separately for different locations, according to the respective rates in each location. Downside of the latter is that it is hard to say something about the distribution for areas with low activity. The first options thus seems best.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sim_and_actual(postcode):\n",
    "    y = peak_incidents[peak_incidents[\"dim_incident_postcode_digits\"]==postcode][\"interarrival_time\"].astype(float)\n",
    "    L = y.mean()\n",
    "    x = np.random.exponential(L, len(y))\n",
    "    plot_double_hist(x, y, [\"simulated\", \"actual\"], bins=round(len(x)/2), xlim=50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_sim_and_actual(postcodes[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating separate interarrival times for different locations also seems possible for the busiest postal codes, but maybe not for less busy areas..\n",
    "\n",
    "In any case, we still need to distinguish between different types, priorities, and the required number of vehicles (of different types). This could be done using multinomial distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Probabilities of demand locations, incident types, priorities, number of vehicles, and building functions (response time targets)\n",
    "\n",
    "### 2.1 probability that an incident occurs in a specific demand location\n",
    "\n",
    "We are looking for the probability that an incident occurs in location x, given that an incident occurs somewhere in the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_postcode_digits(incident_data, remove_missing=True):\n",
    "    if remove_missing:\n",
    "        incident_data = incident_data[~incident_data[\"dim_incident_postcode\"].isnull()].copy()\n",
    "    incident_data[\"dim_incident_postcode_digits\"] = incident_data[\"dim_incident_postcode\"].str[0:4]\n",
    "    return incident_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = add_postcode_digits(incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_per_demand_location(incident_data, location=\"postcode_digits\"):\n",
    "    \"\"\" Calculate the proportion of incidents that happens in every demand location. \n",
    "    \n",
    "    :param incident_data: Pandas DataFrame with incident data.\n",
    "    :param location: How to define the demand locations. Must be one of [\"postcode_digits\", \"grid\"].\n",
    "    :return: Tuple of two numpy arrays with the probabilities and demand location names respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    if location==\"postcode_digits\":\n",
    "        incident_data.sort_values(\"dim_incident_postcode_digits\", ascending=True, inplace=True)\n",
    "        incident_data = incident_data.groupby(\"dim_incident_postcode_digits\")[\"dim_incident_id\"].count() / len(incident_data)\n",
    "        return np.array(incident_data), np.array(incident_data.index)\n",
    "    else:\n",
    "        print(\"Only 'postcode_digits' is currently implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_probs, demand_location_names = get_prob_per_demand_location(incidents)\n",
    "print(sum(location_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demand_location_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incidents[incidents[\"dim_incident_postcode\"].isnull()]\n",
    "sum(incidents[\"dim_incident_postcode\"].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of incidents (764) has no postal code. These are mostly outside fires (buitenbrand) and general aid (algemene hulpverlening). There are however street names, so the postal code should be obtainable. Given the uncertainty regarding the definition of demand locations, we do not go into this now. Specifically, we might use a grid layout instead of the postal codes, in which case this is not a problem anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 distribution of incident types for each demand location\n",
    "We should determine this distribution separately for each demand location, because different demographic and geographic characteristics will lead to different distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_probs_per_location(incident_data, location=\"postcode_digits\"):\n",
    "    if location==\"postcode_digits\":\n",
    "        incident_data.sort_values(\"dim_incident_postcode_digits\", ascending=True, inplace=True)\n",
    "        incident_data = incident_data.groupby([\"dim_incident_postcode_digits\", \"dim_incident_incident_type\"])[\"dim_incident_id\"].count().reset_index()\n",
    "        incident_data[\"type_prob_per_location\"] = incident_data.groupby(\"dim_incident_postcode_digits\")[\"dim_incident_id\"].apply(lambda x: x/x.sum())\n",
    "        probs_per_location = pd.pivot_table(incident_data, index=\"dim_incident_incident_type\", columns=\"dim_incident_postcode_digits\", \n",
    "                                            values=\"type_prob_per_location\").fillna(0)\n",
    "        types = np.array(probs_per_location.index)\n",
    "        return {loc : list(probs_per_location[loc]) for loc in probs_per_location.columns}, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict, type_names = get_type_probs_per_location(incidents)\n",
    "type_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict[\"1011\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 probabilities of priority levels given the incident type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prio_probabilities_per_type(incident_data):\n",
    "    \"\"\" Create dictionary with the probabilities of having priority 1, 2, and 3 for \n",
    "        every incident type. \n",
    "        \n",
    "    :param incident_data: Pandas DataFrame containing the log of incidents from which\n",
    "                          the probabilities should be obtained.\n",
    "    :return: Dictionary with incident type names as keys and lists of length 3 as elements.\n",
    "             The lists have probabilities of prio 1, 2, 3 in position 0, 1, 2 respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    prio_per_type = incident_data.groupby([\"dim_incident_incident_type\", \"dim_prioriteit_prio\"])[\"dim_incident_id\"].count().reset_index()\n",
    "    prio_per_type[\"prio_probability\"] = prio_per_type.groupby([\"dim_incident_incident_type\"])[\"dim_incident_id\"].apply(lambda x: x/x.sum())\n",
    "    prio_probabilities = pd.pivot_table(prio_per_type, columns=\"dim_incident_incident_type\", values=\"prio_probability\", index=\"dim_prioriteit_prio\").fillna(0)\n",
    "    return {col : list(prio_probabilities[col]) for col in prio_probabilities.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prio_dict = get_prio_probabilities_per_type(incidents)\n",
    "prio_dict[\"Assistentie Ambulance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents[[\"dim_classificatie_object_type\", \"dim_incident_brandoorzaak_brandschademodel\", \n",
    "           \"dim_classificatie_brand_type\", \"meldingsclassificatie_1\", \"meldingsclassificatie_2\", \"meldingsclassificatie_3\", \"profiel_object\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 distribution over number of vehicles required per incident type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vehicle_requirements_probabilities(incident_data, deployment_data):\n",
    "    \"\"\" Calculate the probabilities of needing a number of vehicles of a specific type \n",
    "        for a specified incident type.\n",
    "    :param deployment_data: Pandas DataFrame with the deployment data.\n",
    "    :returns: nested dictionary like {\"incident type\" : {\"vehicle type\" : {'nr of vehicles' : prob}}}.\n",
    "    \"\"\"\n",
    "        \n",
    "    # add incident type to the deployment data\n",
    "    deployment_data = deployment_data.merge(incident_data[[\"dim_incident_id\", \"dim_incident_incident_type\"]], \n",
    "                                            left_on=\"hub_incident_id\", right_on=\"dim_incident_id\", how=\"left\")\n",
    "\n",
    "    # create mock column to count\n",
    "    deployment_data[\"count\"] = 1\n",
    "    \n",
    "    # count number of vehicles per incident and vehicle type\n",
    "    deployment_data = deployment_data.groupby([\"dim_incident_incident_type\", \"hub_incident_id\",\n",
    "                                               \"voertuig_groep\"])[\"count\"].count().reset_index()\n",
    "    \n",
    "    # retrieve dictionary for each incident type\n",
    "    types = deployment_data[\"dim_incident_incident_type\"].unique()\n",
    "    prob_dict = dict()\n",
    "    # please forgive me for the awful piece of code that follows\n",
    "    for ty in types:\n",
    "        \n",
    "        # get information for this incident type\n",
    "        temp = deployment_data[deployment_data[\"dim_incident_incident_type\"] == ty].copy()\n",
    "        nr_incidents = temp[\"hub_incident_id\"].nunique()\n",
    "        vehicles = temp[\"voertuig_groep\"].unique()\n",
    "        \n",
    "        # get the probabilities\n",
    "        temp = temp.groupby([\"voertuig_groep\", \"count\"])[\"hub_incident_id\"].count().unstack().fillna(0)\n",
    "        temp[0] = nr_incidents - temp.sum(axis=1)\n",
    "        temp = temp / nr_incidents\n",
    "        temp = temp.T\n",
    "        prob_dict[ty] = {v : dict(temp[v][temp[v]!=0]) for v in temp.columns}\n",
    "\n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the speed of the above function, since it uses a for loop and dict comprehension.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    x = get_vehicle_requirements_probabilities(incidents, deployments)\n",
    "\n",
    "from timeit import timeit\n",
    "print(\"Function evaluated in {} seconds.\".format(round(timeit(test, number=1), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Distribution of building function per demand location / postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents[\"inc_dim_object_functie\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_function_probs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_function_probs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_function_probs2 = building_function_probs.copy()\n",
    "building_function_probs2.groupby(\"dim_incident_postcode_digits\")\\\n",
    "                        .apply(lambda x: x.groupby(\"dim_incident_incident_type\")\\\n",
    "                                          .apply(lambda y: print(pd.pivot_table(y, columns=\"inc_dim_object_functie\", values=\"building_function_probs\").to_dict())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_building_function_probs(incident_data):\n",
    "    \"\"\" Calculate the probability of an incident occuring in a certain type of building\n",
    "        given the demand location and incident type.\n",
    "        \n",
    "    :param incident_data: Pandas DataFrame with the incident data.\n",
    "    :return: nested dictionary like {\"location\" : {\"incident type\" : {\"building\" : prob}}}\n",
    "    \"\"\"\n",
    "    print(sum(incident_data[\"dim_incident_postcode_digits\"] == \"1117\"))\n",
    "    incident_data[\"inc_dim_object_functie\"] = incident_data[\"inc_dim_object_functie\"].fillna(\"unknown\")\n",
    "    building_function_probs = incident_data.groupby([\"dim_incident_postcode_digits\", \"dim_incident_incident_type\", \"inc_dim_object_functie\"])\\\n",
    "                                           [\"dim_incident_id\"]\\\n",
    "                                           .count()\\\n",
    "                                           .reset_index()\n",
    "\n",
    "    print(sum(building_function_probs[\"dim_incident_postcode_digits\"] == \"1117\"))\n",
    "    print(building_function_probs.shape)\n",
    "    building_function_probs[\"building_function_probs\"] = \\\n",
    "                           building_function_probs.groupby([\"dim_incident_postcode_digits\", \"dim_incident_incident_type\"])\\\n",
    "                           [\"dim_incident_id\"]\\\n",
    "                           .transform(lambda x: x/x.sum())\n",
    "\n",
    "    print(building_function_probs.shape)\n",
    "    \n",
    "    building_dict = \\\n",
    "        building_function_probs.groupby([\"dim_incident_postcode_digits\", \"dim_incident_incident_type\"])\\\n",
    "                               [[\"inc_dim_object_functie\", \"building_function_probs\"]]\\\n",
    "                               .apply(lambda x: {x[\"inc_dim_object_functie\"].iloc[i] : x[\"building_function_probs\"].iloc[i] for i in range(len(x))})\\\n",
    "                               .unstack()\\\n",
    "                               .T\\\n",
    "                               .to_dict()\n",
    "\n",
    "    \n",
    "    return building_dict\n",
    "    \n",
    "test = get_building_function_probs(incidents)\n",
    "test[\"1117\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents[incidents[\"dim_incident_postcode_digits\"]==\"1117\"][\"inc_dim_object_functie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"dim_incident_postcode_digits\", \"dim_incident_incident_type\", \"inc_dim_object_functie\", \"building_function_probs\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mapping from building function to response time target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {'Bijeenkomstfunctie' : 10,\n",
    "           'Industriefunctie' : 8,\n",
    "           'Woonfunctie' : 8,\n",
    "           'Straat' : 10,\n",
    "           'Overige gebruiksfunctie' : 10,\n",
    "           'Kantoorfunctie' : 10,\n",
    "           'Logiesfunctie' : 8,\n",
    "           'Onderwijsfunctie' : 8,\n",
    "           'Grachtengordel' : 10,\n",
    "           'Overig' : 10,\n",
    "           'Winkelfunctie' : 5,\n",
    "           'Kanalen en rivieren' : 10,\n",
    "           'nan' : 10,\n",
    "           'Trein' : 5,\n",
    "           'Sportfunctie' : 10,\n",
    "           'Regionale weg' : 10,\n",
    "           'Celfunctie' : 5,\n",
    "           'Tram' : 5,\n",
    "           'Sloten en Vaarten' : 10,\n",
    "           'Gezondheidszorgfunctie' : 8,\n",
    "           'Lokale weg' : 5,\n",
    "           'Polders' : 10,\n",
    "           'Haven' : 10,\n",
    "           'Autosnelweg' : 10,\n",
    "           'Meren en plassen' : 10,\n",
    "           'Hoofdweg' : 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
